{"0": {
    "doc": "About",
    "title": "About",
    "content": " ",
    "url": "/about/",
    "relUrl": "/about/"
  },"1": {
    "doc": "About",
    "title": "How to site is built",
    "content": "The site is generated with Jekyll jekyllrb.com . The base theme used is just-the-docs, which is found at GitHub: jekyll / just-the-docs . You can find the source code for Jekyll at GitHub: jekyll / jekyll . ",
    "url": "/about/#how-to-site-is-built",
    "relUrl": "/about/#how-to-site-is-built"
  },"2": {
    "doc": "Chef",
    "title": "Chef Kitchen",
    "content": ". | Background | What is Chef? | Chef Infra | Starting out with Chef | Chef-Run | Policyfiles/Berkshelf/Knife . | Policyfiles | . | Attributes | Resource guards | Iteration | Winrm second hop | How to customise an existing resource? | Chocolately package | Use paths on windows without pain | Resources | . ",
    "url": "/chef/#chef-kitchen",
    "relUrl": "/chef/#chef-kitchen"
  },"3": {
    "doc": "Chef",
    "title": "Background",
    "content": "Un-testable infrastructure is more hassle than it’s worth. Or at least, it’s difficult to deploy updates to the infrastructure, unless you’re already very familiar with it. Chef is a configuration-management toolkit written in Ruby. You can write ‘recipes’ (scripts) that will setup a machine for you. It’s part of the infrastructure-as-code movement. In dev-ops, if it deploys it works. That is the test. Correct? Well, I disagree. I think dev-ops requires solid automated tests, just like any other bit of your code-base. General cavets apply. Why introduce something like Chef if it becomes hard to change? While Chef offers the possibility of reducing your operation burden provisioning machines, untested Chef recipes increase your deployment friction. Thus, I believe, it’s important to consider how you can test recipes as you write ones for your environment. I.e. Chef might be great at helping you setup lots of machines, but how do you change your Chef setup without knowing you haven’t borked all your machine setups? Hmm. Thankfully, Chef provides some tools to help you do your job. ",
    "url": "/chef/#background",
    "relUrl": "/chef/#background"
  },"4": {
    "doc": "Chef",
    "title": "What is Chef?",
    "content": "You can find out about Chef at https://www.chef.io/ . You’ll find the company has really over-used the chef/kitchen/food/knife/supermarket analogy. Every bit of their product seems to be named after some part of the food preparation process. I guess they are analogising cooking your machines with provisioning your food. But I find the naming convention a bit irritating. However, it is distinctive. ",
    "url": "/chef/#what-is-chef",
    "relUrl": "/chef/#what-is-chef"
  },"5": {
    "doc": "Chef",
    "title": "Chef Infra",
    "content": "While Chef offers a few products, I believe the core of the project started around what is now called Chef Infra https://www.chef.io/products/chef-infra/ Visit the website for their sales pitch around how Chef makes your sex-life better. I believe, in essence, Chef runs an executable on each machine you want to configure via chef. This is called the Chef client. You pass the chef client a recipe or a bunch of recipes, written in a Ruby-based Chef-developed domain-specific-language. The important idea is the recipes are meant to be idempotent (idempotent means the recipe can be run again and again and the result will always be the same). This is meant to mean that you can bring your machine into ‘compliance’ with the recipe by just re-running it whenever. As chef recipes are extendable and you can write your own, obviously you can break the idempotency of the recipe. But that’s your responsibility. Apart from the idea of idempotency and providing a toolkit of recipes you can use, I don’t think there’s much else special about Chef. It is written in Ruby which will please some and annoy others. There are competitors, for example like Ansible written in Python. And for your environment, you may just be best considering the language your team is most comfortable with. There’s not a whole lot of point introducing Chef if your working environment has a strong preference for Python. Opt for ansible then. Or, etc, whatever configuration toolkit uses a language your team members are most familiar with. Infra documentation begins at https://docs.chef.io/chef_overview/ . ",
    "url": "/chef/#chef-infra",
    "relUrl": "/chef/#chef-infra"
  },"6": {
    "doc": "Chef",
    "title": "Starting out with Chef",
    "content": "Chef have quite polished tutorials at https://learn.chef.io. Though, they also leave a lot of questions unanswered. They aren’t particularly comprehensive. But give a reasonable introduction. You want to check that you have chef installed on your development machine. Run . &gt;chef --version ChefDK version: 4.7.73 Chef Infra Client version: 15.7.32 Chef InSpec version: 4.18.51 Test Kitchen version: 2.3.4 Foodcritic version: 16.2.0 Cookstyle version: 5.20.0 . Note, Chef is fundamentally about provisioning machines. So, unless you want to alter your development machine, you need some way to spawn new machines. Chef typically uses this Test Kitchen to run tests on recipes. Check Test Kitchen is available, run . &gt;kitchen --version Test Kitchen version 2.3.4 . Test kitchen can be extended to start any sort of machine, but most of the tutorials show you have to use VirtualBox and Vagrant to start machines. Check Vagrant is available, run . &gt;vagrant --version vagrant 2.2.9 . What is Vagrant? It’s a tool for managing (starting/stopping/deleting) virtual-machines, using providers like VMWare, AWS, Docker, VirtualBox etc. Create a directory called ‘learn-chef-infra’ then generate the minimum required files using a generate command. Run . &gt;mkdir chef-learn-infra &gt;cd chef-learn-infra &gt;chef generate cookbook learn_chef . Generating cookbook learn_chef . | Ensuring correct cookbook content | Committing cookbook files to git | . Your cookbook is ready. Type cd learn_chef to enter it. There are several commands you can run to get started locally developing and testing your cookbook. Type delivery local --help to see a full list of local testing commands. Why not start by writing an InSpec test? Tests for the default recipe are stored at: test/integration/default/default_test.rb . If you’d prefer to dive right in, the default recipe can be found at: recipes/default.rb . You’ll see that this has created a bunch of files in the directory. C:\\dev\\chef\\learn-chef-infra\\learn_chef C:\\dev\\chef\\learn-chef-infra\\learn_chef\\.delivery C:\\dev\\chef\\learn-chef-infra\\learn_chef\\recipes C:\\dev\\chef\\learn-chef-infra\\learn_chef\\spec C:\\dev\\chef\\learn-chef-infra\\learn_chef\\test C:\\dev\\chef\\learn-chef-infra\\learn_chef\\.gitignore C:\\dev\\chef\\learn-chef-infra\\learn_chef\\CHANGELOG.md C:\\dev\\chef\\learn-chef-infra\\learn_chef\\chefignore C:\\dev\\chef\\learn-chef-infra\\learn_chef\\kitchen.yml C:\\dev\\chef\\learn-chef-infra\\learn_chef\\LICENSE C:\\dev\\chef\\learn-chef-infra\\learn_chef\\metadata.rb C:\\dev\\chef\\learn-chef-infra\\learn_chef\\Policyfile.rb C:\\dev\\chef\\learn-chef-infra\\learn_chef\\README.md C:\\dev\\chef\\learn-chef-infra\\learn_chef\\.delivery\\project.toml C:\\dev\\chef\\learn-chef-infra\\learn_chef\\recipes\\default.rb C:\\dev\\chef\\learn-chef-infra\\learn_chef\\spec\\unit C:\\dev\\chef\\learn-chef-infra\\learn_chef\\spec\\spec_helper.rb C:\\dev\\chef\\learn-chef-infra\\learn_chef\\spec\\unit\\recipes C:\\dev\\chef\\learn-chef-infra\\learn_chef\\spec\\unit\\recipes\\default_spec.rb C:\\dev\\chef\\learn-chef-infra\\learn_chef\\test\\integration C:\\dev\\chef\\learn-chef-infra\\learn_chef\\test\\integration\\default C:\\dev\\chef\\learn-chef-infra\\learn_chef\\test\\integration\\default\\default_test.rb . • The things inside the \\.directory can be ignored. • \\spec directory basically contain unit-tests for your ruby recipes • \\recipes are where you use Chef’s Ruby DSL to describe how you want your machines configured • \\test provide integration tests that Test Kitchen can run. This will allow you to check the recipes actually work as expected on specific machines. • The rest of the files are basically configurations files . You’ll probably notice the new directory generated is also a git repository. If you have vagrant installed, you should be able to run kitchen list. (Note, kitchen list is specific to the directory you are in. It reads the configuration files, primarily kitchen.yml. So you must be in the correct directory to run it.) . &gt;cd learn_chef &gt;kitchen list Instance Driver Provisioner Verifier Transport Last Action Last Error default-ubuntu-1804 Vagrant ChefZero Inspec Ssh &lt;Not Created&gt; &lt;None&gt; default-centos-7 Vagrant ChefZero Inspec Ssh &lt;Not Created&gt; &lt;None&gt; . This lists the (virtual) machines that the kitchen.yml is configured to run the integration tests against. Note, the default driver is Vagrant. You can create your own drivers if you’re environment has specific ways to create virtual-machines or you can use the provided drivers for things like Google, AWS, etc. The listed machines haven’t actually been created yet. You can get Kitchen to create the virtual machines, will itself will just ask Vagrant to do this, and then will wait for an SSH server to start on the new VMs. (As the transport is also set to SSH. Again, this can be changed if you need.) Once the SSH is started, it will connect to the machine and then will issue commands to install the chef client executable on the VM. It will transfer the recipe across to the machine and then will run the recipe of the machine. You do all this in one go by running kitchen converge. Pretty neat. &gt;kitchen converge … &lt;runs off&gt; . Then you can run kitchen list again and it’ll indicate the last action on the machines worked out. &gt;kitchen list Instance Driver Provisioner Verifier Transport Last Action Last Error default-ubuntu-1804 Vagrant ChefZero Inspec Ssh Converged &lt;None&gt; default-centos-7 Vagrant ChefZero Inspec Ssh Converged &lt;None&gt; . You can login to the machine that Kitchen has created using ‘kitchen login’. Writing a recipe . You can write recipes in either yaml or ruby. I’ll use Ruby given I like the flexibility of a programming language. You can write the recipe inside the default.rb (i.e. at learn-chef-infra/learn_chef/recipes/default.rb) or you can create a new ruby file and import it into default.rb. Create a file at learn-chef-infra/learn_chef/recipes/learn-chef.rb . include_recipe \"learn_chef::learn-chef\" . For a ruby recipe, you use a do..end ruby block (basically a closure) . file \"/etc/mota\" do content \"its better in ruby though\" end . Or you can start a web server like so package ‘apache2’ . file \"/var/www/html/index.html\" do content \"hello moto\" end service 'apache2' do action [:enable, :start] end . I think it’s probably worth noting that recipes are executed from top to bottom. I believe. You can get rid of the stuff created by kitchen with kitchen destroy. Otherwise, kitchen leaves the machines around between converges, which does help to speed up the tests. &gt;kitchen destroy -----&gt; Starting Test Kitchen (v2.3.4) -----&gt; Destroying &lt;default-ubuntu-1804&gt;... ==&gt; default: Forcing shutdown of VM... ==&gt; default: Destroying VM and associated drives... Vagrant instance &lt;default-ubuntu-1804&gt; destroyed. Finished destroying &lt;default-ubuntu-1804&gt; (0m8.63s). -----&gt; Test Kitchen is finished. (0m10.80s) . ",
    "url": "/chef/#starting-out-with-chef",
    "relUrl": "/chef/#starting-out-with-chef"
  },"7": {
    "doc": "Chef",
    "title": "Chef-Run",
    "content": "Chef-run is a tool to execute ad-hoc tasks on one or more target nodes using Chef. (Documentation here https://www.chef.sh/docs/reference/chef-run/) It is installed if you install Chef Workstation (which is basically a sort of development environment, documentation here https://www.chef.sh/docs/chef-workstation/getting-started/). You can use it to run recipes or resources on machines, in an ad-hoc fashion. &gt;chef-run web1 file hello.txt content=’hello world’ [✔] Packaging cookbook... done! [✔] Generating local policyfile... exporting... done! [✔] Applying file[hello.txt] from resource to target. └── [✔] [web1] Successfully converged file[hello.txt]. This will connect to a machine called ‘web1’ (note, this would need to be configured as an alias), and it will create the file on the machine. Likewise, we could then check the contents of the file, and then run another ad-hoc command to delete the file. &gt;ssh web1 cat /hello.txt hello world &gt;chef-run web1 file hello.txt action=delete [✔] Packaging cookbook... done! [✔] Generating local policyfile... exporting... done! [✔] Applying file[hello.txt] from resource to target. └── [✔] [web1] Successfully converged file[hello.txt]. Rather than just running ad-hoc resources invocations, we can also run recipes or cookbooks. &gt;chef-run web1 recipe.rb &gt;chef-run web1 cookbook1 . Note, that a recipe is a standalone file. Whereas, a cookbook is a directory with a metadata.rb and a recipes directory. metadata.rb contains information like what other cookbooks this cookbook depends upon, plus states a version number of the cookbook. A metadata file looks something like this: . name 'base' maintainer 'The Authors' maintainer_email 'you@example.com' license 'All Rights Reserved' description 'Installs/Configures base' long_description 'Installs/Configures base' version '0.1.0' chef_version '&gt;= 13.0' depends 'os-hardening' . Note, while a metadata file might describe what the cookbook depends upon, it doesn’t tell chef how to find those dependencies. That is control by a berksfile or a policyfile. For example, the hardening cookbook can be found at https://supermarket.chef.io/cookbooks/os-hardening. See the section on PolicyFiles for more information. Recipes directory contains other recipes, the default being ‘default.rb’ . A cookbook can also contain a ‘templates’ directory, that contains ‘.erb’ files (Ruby template files). There is a template resource (documentation here https://docs.chef.io/templates/ ) can use the template to create files on the clients. template ‘/var/www/html/index.html’ do source ‘index.html.erb’ end . This would create the index.html on the client provided the templates directory contains an ‘index.html.erb’ file like so . &lt;html&gt; &lt;body&gt; &lt;p&gt;This is chef client node &lt;%=node[‘hostname’]%&gt; &lt;/p&gt; &lt;/body&gt; &lt;/html&gt; . A cookbook can also contain an attributes directory. Attributes can be generated with chef generate attribute &lt;cookbook_path&gt; &lt;name&gt; . A cookbook can also contain a files directory. ",
    "url": "/chef/#chef-run",
    "relUrl": "/chef/#chef-run"
  },"8": {
    "doc": "Chef",
    "title": "Policyfiles/Berkshelf/Knife",
    "content": "The older version of a PolicyFile was the Berks file. Basically, they are about specifying where dependencies ought to be fetched from. I believe knife is basically a way of fetching/installing dependencies. For example, for https://supermarket.chef.io/cookbooks/os-hardening it lists as ways to install it: . | Berkshelf cookbook ‘os-hardening’, ‘~&gt; 4.0.0’ | Policyfile Cookbook ‘os-hardening’, ‘~&gt; 4.0.0’, :supermarket | Knife knife supermarket install os-hardening knife supermarket download os-hardening . | . Policyfiles . A policyfile is “Policyfile.rb” that sits alongside the metadata.rb of a recipe. “A Policyfile declares the name, run_list, sources, and attributes for a node or group of nodes. Policyfiles also handle all dependency resolution for your cookbooks.”…“Policyfiles give you the confidence that the version of cookbook you specify will always be the one deployed.”…“Policyfiles give you the confidence that the version of cookbook you specify will always be the one deployed.” . You can generate a policyfile when generating the cookbook by using -P switch . chef generate cookbook &lt;name&gt; -P . Or you can generate a policyfile with a separate invocation . chef generate policyfile &lt;name&gt; . A policyfile looks like this . # Policyfile.rb - Describe how you want Chef Infra Client to build # your system. # For more information on the Policyfile feature, visit # https://docs.chef.io/policyfile.html # A name that describes what the system you're building with Chef # does. Used to reference this policyfile on Chef server and must be # thus unique. name 'base' # Where to find external cookbooks if they are not specifically # declared in the cookbook section below default_source :supermarket # run_list: chef-client will run these recipes in the order # specified. run_list 'base::default' # Specify a custom source for a single cookbook. Provide local # cookbooks that if are specified as a dependency will be found # before chef looks in supermarket. cookbook 'base', path: '.' cookbook 'hardening', path: '../hardening' . Having defined the policyfile, we need to resolve the listed dependencies to produce a Policyfile.lock.json that ensures reproduction. We run . &gt;chef install cookbooks/base/Policyfile.rb Building policy base Expanded run list: recipe[base::default] Caching Cookbooks... Installing base &gt;= 0.0.0 from path Installing hardening &gt;= 0.0.0 from path Using os-hardening 4.0.0 Using windows-hardening 0.9.1 Using windows-security-policy 0.3.9 Lockfile written to C:/dev/chef/lcr-policyfiles-getstarted/cookbooks/base/Policyfile.lock.json Policy revision id: ca474c6e5bca2eda927549bd33efe1f9ccc7e74e26c2922b0a4d57805555cef5 . Then if we re-run the same command, it just uses the lockfile direct . &gt;chef install cookbooks/base/Policyfile.rb Installing cookbooks from lock Installing base 0.1.0 Installing hardening 0.1.0 Using os-hardening 4.0.0 Using windows-hardening 0.9.1 Using windows-security-policy 0.3.9 . Running chef install reads the Policyfile.rb and creates a Policyfile.lock.json file. This Policyfile.lock.json file is the actual policy used by Chef Client and contains unique references to the cookbooks in the run_list. The Policyfile.rb file is really only used as a human readable/editable file used to create the related Policyfile.lock.json file. The Policyfile.lock.json file consolidates all dependencies in the run_list. This file gets downloaded to your node and read by chef-client. The chef-client will then download the precise versions of all dependencies and run them locally. The Policyfile.lock.json specifies not only the cookbooks required, but also the exact SHA fingerprint of all of the associated files and a checksum of the cookbook contents. If the contents change in any way, then the checksum will change and chef-client not run the policy. If you were to use this same lock file on another workstation, then you can be certain it will use the same version of the cookbooks. If it cannot find these versions, then chef-client will return an error. If you have made changes to the policyfile, you can update it with . &gt;chef update Policyfile.rb .   . ",
    "url": "/chef/#policyfilesberkshelfknife",
    "relUrl": "/chef/#policyfilesberkshelfknife"
  },"9": {
    "doc": "Chef",
    "title": "Attributes",
    "content": "The attributes folders basically seems to be a way of storing variables that recipes can access. When OHAI runs, it sets the attributes of a node (a node is an object that represents the machine being configured by chef). So you can get attributes that inform you about what platform or machine the recipe is being run on, so that’s pretty good for dynamic data. But you can also define your own attributes, which seem to be more or less arguments to the recipes you’ve created, I think. This seems to explain it more https://docs.aws.amazon.com/opsworks/latest/userguide/cookbooks-101-basics-attributes.html . ",
    "url": "/chef/#attributes",
    "relUrl": "/chef/#attributes"
  },"10": {
    "doc": "Chef",
    "title": "Resource guards",
    "content": "Quite often you only want to run a resource if something is missing or whatever. This is what is a resource ‘guard’ is for, and you can use them on any resource. There seem to be two ‘only_if’ and ‘not_if’. Only_if means the resource will run if the condition is true. Not_if prevents the resource is not run if true. powershell_script \"Connect to #{path}\" do code \"net use #{path} /USER:&lt;username&gt; /PERSISTENT:YES &lt;pass&gt;\" # Only run if the directory isn't already available not_if { ::Dir.exist?(path) } end . ",
    "url": "/chef/#resource-guards",
    "relUrl": "/chef/#resource-guards"
  },"11": {
    "doc": "Chef",
    "title": "Iteration",
    "content": "Maybe you want to do the same resource for multiple things? Luckily, you can just run an iteration loop. I suppose this really shows that the DSL is just ruby. AWS documentation has some nice examples on this https://docs.aws.amazon.com/opsworks/latest/userguide/cookbooks-101-basics-ruby.html#cookbooks-101-basics-ruby-iteration . [ \"/srv/www/config\", \"/srv/www/shared\" ].each do |path| directory path do mode 0755 owner 'root' end end . And you can iterate over whatever iterable ruby allows, including hash tables . { \"/srv/www/config\" =&gt; 0644, \"/srv/www/shared\" =&gt; 0755 }.each do |path, mode_value| directory path do mode mode_value owner 'root' group 'root' recursive true action :create end end . ",
    "url": "/chef/#iteration",
    "relUrl": "/chef/#iteration"
  },"12": {
    "doc": "Chef",
    "title": "Winrm second hop",
    "content": "There is an authentication issue with win-rm accessing remote fileshares called the second hop problem. I was searching for a while how to fix it, and I struggled. Eventually I found there’s a parameter called ‘elevated’ that if you set to true for the winrm transport, it’ll run as a service and this seems to get around the second hop issues. I.e. like this in the kitchen.yml . --- driver: name: custom-vms vm_user: &lt;user&gt; vm_token: &lt;token&gt; platforms: - name: test-win10-20h1 driver: vmtemplate: test-win10-20h1 transport: name: winrm elevated: true username: &lt;user&gt; password: &lt;pass&gt; . I had found this problem doesn’t exist with OpenSSH, so you can install it but you need to configure the private key etc. pub_key = &lt;&lt;-EOH &lt;PUBLIC SSH KEY HERE&gt; EOH ssh_script = &lt;&lt;-EOH choco install OpenSSh -y --params /SSHServerFeature Set-Service -Name sshd -StartupType 'Automatic' New-NetFirewallRule -Name sshd -DisplayName 'OpenSSH Server (sshd)' -Enabled True -Direction Inbound -Protocol TCP -Action Allow -LocalPort 22 New-ItemProperty -Path \"HKLM:\\\\SOFTWARE\\\\OpenSSH\" -Name DefaultShell -Value \"C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe\" -PropertyType String -Force EOH powershell_script 'Setup Open-Ssh service' do code ssh_script end file 'C:\\ProgramData\\ssh\\ssh_host_rsa_key.pub' do content pub_key end file 'C:\\ProgramData\\ssh\\ssh_host_rsa_key' do action :delete end . ",
    "url": "/chef/#winrm-second-hop",
    "relUrl": "/chef/#winrm-second-hop"
  },"13": {
    "doc": "Chef",
    "title": "How to customise an existing resource?",
    "content": "Let’s say I want to use in the in-built chef recipe, chocolatey_package, but I need to customise it so that after it runs, it also runs ‘refreshenv.bat’. I had a problem that even though I’ve installed a resource, the shell sessions path isn’t updated to know where Java is. ",
    "url": "/chef/#how-to-customise-an-existing-resource",
    "relUrl": "/chef/#how-to-customise-an-existing-resource"
  },"14": {
    "doc": "Chef",
    "title": "Chocolately package",
    "content": "# Install Java from a local chocolately mirror chocolatey_package 'OpenJDKJre' do package_name 'OpenJDKjre' source '\\\\\\\\test.corpb.local\\\\ChocolateyMirror' version \"11.0.7.10\" end # I end up doing a hack, otherwise java executable can’t be found # Seems there may be an issue getting new envvars. Powershell_script ‘run java’ do code &lt;&lt;-EOH import-module \"C:\\\\ProgramData\\\\chocolatey\\\\helpers\\\\chocolateyProfile.psm1\" Update-SessionEnvironment java -jar 'C:\\\\jenkins-swarm\\\\swarm-client-3.9.jar' EOH end . ",
    "url": "/chef/#chocolately-package",
    "relUrl": "/chef/#chocolately-package"
  },"15": {
    "doc": "Chef",
    "title": "Use paths on windows without pain",
    "content": "Paths of windows in chef recipes normally look like this ‘C:\\some\\path\\hurts’ . You can try various ruby solutions to allow yourself to avoid the double backslash. I never succeeded getting that to work. This suggestion came from https://www.slideshare.net/opscode/chef-conf-windowsdougireton . # include Windows::Helper from Opscode Windows Cookbook ::Chef::Recipe.send(:include, Windows::Helper) # now you can call helper methods like win_friendly_path my_file = win_friendly_path('c:/no/insane/backslashes.tmp') execute 'My file' do command my_file end . ",
    "url": "/chef/#use-paths-on-windows-without-pain",
    "relUrl": "/chef/#use-paths-on-windows-without-pain"
  },"16": {
    "doc": "Chef",
    "title": "Resources",
    "content": ". | https://zwischenzugs.com/2017/11/25/ten-things-i-wish-id-known-about-chef/ | AWS actually has some really good documentation to help people become acquainted with chef. https://docs.aws.amazon.com/opsworks/latest/userguide/cookbooks-101-basics-ruby.html | . ",
    "url": "/chef/#resources",
    "relUrl": "/chef/#resources"
  },"17": {
    "doc": "Chef",
    "title": "Chef",
    "content": " ",
    "url": "/chef/",
    "relUrl": "/chef/"
  },"18": {
    "doc": "Groovy",
    "title": "Groovy",
    "content": ". | Groovy.bat | Groovy repl | Debugger | Groovy console | Data types | Control structures | Functions | Closures | Classes | Knowing how to do stuff | Importing packages | External packages, Grape | References | . Groovy is a java-based scripting language a ‘java-script’ - haha. There’s not really such a thing as the groovy runtime. Groovy is a way to generate bytecode for the JVM. Groovy source-code goes through the groovy compiler (which itself runs on the JVM I presume) to produce JVM byte-code. groovy-download . ",
    "url": "/groovy/",
    "relUrl": "/groovy/"
  },"19": {
    "doc": "Groovy",
    "title": "Groovy.bat",
    "content": "C:\\Users\\donal.mee&gt; get-command groovy.bat | select -ExpandProperty source C:\\tools\\groovy-2.5.1\\bin\\groovy.bat C:\\Users\\donal.mee&gt; groovy.bat error: neither -e or filename provided Usage: groovy [options] [filename] [args] The Groovy command line processor. -cp, -classpath, --classpath=&lt;path&gt; Specify where to find the class files - must be first argument -D, --define=&lt;property=value&gt; Define a system property --disableopt=optlist[,optlist...] Disables one or all optimization elements; optlist can be a comma separated list with the elements: all (disables all optimizations), int (disable any int based optimizations) -d, --debug Debug mode will print out full stack traces -c, --encoding=&lt;charset&gt; Specify the encoding of the files -e= &lt;script&gt; Specify a command line script -i= [&lt;extension&gt;] Modify files in place; create backup if extension is given (e.g. '.bak') -n Process files line by line using implicit 'line' variable -p Process files line by line and print result (see also -n) -pa, --parameters Generate metadata for reflection on method parameter names (jdk8+ only) -l= [&lt;port&gt;] Listen on a port and process inbound lines (default: 1960) -a, --autosplit[=&lt;splitPattern&gt;] Split lines using splitPattern (default '\\s') using implicit 'split' variable --indy Enables compilation using invokedynamic --configscript=&lt;script&gt; A script for tweaking the configuration options -b, --basescript=&lt;class&gt; Base class name for scripts (must derive from Script) -h, --help Show this help message and exit -v, --version Print version information and exit . This let’s you run your groovy code using a file. Define a file called myfirst.groovy and then put the following code in it . println ‘helloworld!’ . Then execute it by running . &gt;groovy myfirst.groovy helloworld! . ",
    "url": "/groovy/#groovybat",
    "relUrl": "/groovy/#groovybat"
  },"20": {
    "doc": "Groovy",
    "title": "Groovy repl",
    "content": "There is also a groovy repl-like shell at groovysh groovy-sh . ",
    "url": "/groovy/#groovy-repl",
    "relUrl": "/groovy/#groovy-repl"
  },"21": {
    "doc": "Groovy",
    "title": "Debugger",
    "content": "What about a debugger? There doesn’t seem to be any in-built debugger, instead people rely upon the debugger from Eclipise or IDEA (jetbrains). Lol, no built-in debugger wtf. At this point, it’s probably sane to say, just use IDEA to develop Groovy code. It’s pretty nice. ",
    "url": "/groovy/#debugger",
    "relUrl": "/groovy/#debugger"
  },"22": {
    "doc": "Groovy",
    "title": "Groovy console",
    "content": "There is a groovy console at ‘groovyconsole.bat’ which is a little inbuilt ide . def allocate a variable, not a function definition. You can use a colon to write a message. def x = 5 x += 5 println x assert x == 11: \"Value wasn't eleven\" . ",
    "url": "/groovy/#groovy-console",
    "relUrl": "/groovy/#groovy-console"
  },"23": {
    "doc": "Groovy",
    "title": "Data types",
    "content": "Groovy is an ‘optional typed’ language, meaning we can define the type being used or let groovy guess or interpret the type at runtime. You can also avoid a type definition at all. Let’s look at some basic datatypes. | Data type | Groovy keyword | Same data | . | Strings | String | “hello there” | . | Integers | int | 0,1,2,3 | . | Floats | float | 0.5, 3.8 | . | Boolean | Boolean | true, false | . The groovy runtime has coerced the different types into string types. We can improve upon the coercion . &gt;println name + \"is a programmer? \" + isProgrammer.toString().capitalize() donal mee is a programmer? True . The formatting of the float is a bit sucky. There is built-in formatting that we can use, the normal C type string formatting. &gt;println name + “ wishes his salary was \\$” + String.format(“%.2f”, salary) donal mee wishes his salary was $100000.00 . Oh bummer! That didn’t work. It still rounded up the float. We can change from using a float to using the BigDecimal datatype. &gt;BigDecimal salary = 999999.99 &gt;println name + “wishes his salary was \\$” + String.format(“%.2f”, salary) donal mee wishes his salary was $99999.99 . Or we can just output the raw string conversion and that gives us what we want. &gt;BigDecimal salary = 999999.99 &gt;println name + “wishes his salary was \\$” + salary donal mee wishes his salary was $99999.99 . You can also do multiple assignment on a single line . def (String x, int y) = [‘foo’, 42] . In summary: . | You can use optional def to which is basically like auto, just let groovy automatically determine the type. | Or you can be explicit like String donal = \"hello\". | Semi-colons are also optional, perform the same thing as a C semi-colon. A line ending is the same thing as a semi-colon. ‘Optional’ semicolons. | . ",
    "url": "/groovy/#data-types",
    "relUrl": "/groovy/#data-types"
  },"24": {
    "doc": "Groovy",
    "title": "Control structures",
    "content": "Quite good documentation here groovy-docs-semantics . The if statement looks like most if statements . if ( ... ) { ... } else if (...) { ... } else { } . Loops look pretty normal too . String message = ‘’ for (int i = 0; i &lt; 3; i++) { message += ‘Hi ‘ } assert message == ‘Hi Hi Hi ’ . You can also do a more elaborate, comma-separate expression for loop . def facts = [] def count = 5 for (int fact = 1, i = 1; i &lt;= count; i++, fact *= i) { facts &lt;&lt; fact } assert facts == [1,2,6,24,120] . And also, you can use the good old for-in for which works for any kind of collection etc . // iterate over a range def x = 0 for ( i in 0..9) { x += i } assert x == 45 // over a list def x = 0 for ( i in [0,1,2,3,4] ) { x += i } assert x == 10 // iterate over a map (hashtable) def x = 0 def map = [‘abc’:1, ‘def’:2, ‘xyz’:3] for ( v in map ) { x += v.value } assert x == 6 . And there’s also the good old while loop . def (x, y) = [0, 5] while (y-- &gt; 0) { x++ } assert x == 5 assert y == 0 . We can also use a ruby-like .each for iteration . def singers = [0,1,2,3,4] singers.each{x -&gt; println(x)} // or we could use the ‘it’ keyword to do the same thing singers.each{println it} . ",
    "url": "/groovy/#control-structures",
    "relUrl": "/groovy/#control-structures"
  },"25": {
    "doc": "Groovy",
    "title": "Functions",
    "content": "You can define a function that’s return type is determined at runtime using def . def callMe() { ‘Call me on 07812301129’ } assert callMe() == ‘Call me on 07812301129’ . This shows an interesting thing about groovy, just like ruby or powershell. The last thing evaluated in the function is returned. I.e. the ‘return’ keyword is optional. groovy-docs-semantics-optional-keyword. Also, by default, all classes and methods are public, thus there is no need to write . public def callMe() {…} . But of course, being explicit with your types may be better or make things more readable . String getUserName(String firstName, String lastName) { return firstName.substring(0,1).toLowerCase() + lastName.toLowerCase(); } assert getUserName(\"Chris\", \"Behrens\") == \"cbehrens\" : \"getUsername isn't working\" . There is a void keyword that we can use to say a function won’t return anything . void printCred(cred) { // and here we use in-built string interpolation g-string println(“UserName is ${cred}”) } printCred(“Donal Mee”) . ",
    "url": "/groovy/#functions",
    "relUrl": "/groovy/#functions"
  },"26": {
    "doc": "Groovy",
    "title": "Closures",
    "content": "Closures are like anonymous functions, they are defined and then only executed when called . def close = { println ‘hello’ } close() . They are defined using {} curly-braces. What’s the difference between a function and a closure? Quite a few functions in groovy will take a closure as an argument, like the .each() method. So you can write: . (1..3).each({close}) . I assume it’s the use of closures that help create a DSL in groovy. I’m not sure. This is interesting to know. We can pretty easily define parameters a closure takes using the -&gt; symbol. def twoParams = { pm1, pm2 -&gt; println “pm1: $pm1, pm2: $pm2” } twoParams “calif . ",
    "url": "/groovy/#closures",
    "relUrl": "/groovy/#closures"
  },"27": {
    "doc": "Groovy",
    "title": "Classes",
    "content": "Classes are pretty much the same as Java. The relevant documentation is here groovy-docs-oop. They seem pretty straightforward, for example here’s some code . class User { String lastName; String firstName; // initaliser method would be called User public String fullName(){ return this.firstName.substring(0,1).toLowerCase() + this.lastName.toLowerCase() } } String[] firstNames = [\"Bob\", \"Jeff\", \"Roy\"] String[] lastNames = [\"Tibi\", \"Trump\", \"Rogan\"] . The transpose function is acting like pythons zip. [firstNames, lastNames].transpose().each{ fN, fY -&gt; User u = new User(firstName: fN, lastName: fY) println (\"Username is ${u.fullName()}\") } . Groovy supports inheritance and interfaces. It also supports abstract class. And abstract class is one you cannot directly instantiate. Instead, you can define a new class that implements the abstract class and you can instantiate that class. The abstract class itself can define things that are then shared by concrete implemnenter classes. It’s a way of sharing code between classes. There is an abstract and extends keyword. // abstract class cannot be directly instantiated abstract class Person { String lastName; String firstName; public String fullName(){ return this.firstName.substring(0,1).toLowerCase() + this.lastName.toLowerCase() } } // two concrete implementations of the abstract class class Artist extends Person { public String[] Songs; } class Producer extends Person { // just a stub method public void Produce(){}; } Artist dillon = new Artist(firstName: \"Bob\", lastName: \"Dillon\") Producer michael = new Producer(firstName: \"Michael\", lastName: \"Producer\") println dillon.fullName() println michael.fullName() . ",
    "url": "/groovy/#classes",
    "relUrl": "/groovy/#classes"
  },"28": {
    "doc": "Groovy",
    "title": "Knowing how to do stuff",
    "content": "In an above example, I worked out how to get something like python’s zip, which is known as traverse in groovy. The documentation for groovy isn’t as good as python’s. But with a bit of searching, you can find stuff. There seems to be a bit of a lack of standard library documentation. From what I can see, a place that has a list of useful things to know is here groovy-docs-dev-kit. ",
    "url": "/groovy/#knowing-how-to-do-stuff",
    "relUrl": "/groovy/#knowing-how-to-do-stuff"
  },"29": {
    "doc": "Groovy",
    "title": "Importing packages",
    "content": "There are some default imports with groovy. Information around imports and packages can be found at groovy-docs-structure. There’s an import and package keyword. // importing the class MarkupBuilder from the groovy.xml package import groovy.xml.MarkupBuilder // now you can use the MarkupBuilder def xml = new MarkupBuilder() . There’s also a star syntax like python’s import, except it’s appended . // import everything from groovy.xml import groovy.xml.* . You can also alias import like python . Import java.sql.Date as SQLDate . ",
    "url": "/groovy/#importing-packages",
    "relUrl": "/groovy/#importing-packages"
  },"30": {
    "doc": "Groovy",
    "title": "External packages, Grape",
    "content": "Like NPM or Nuget, we can install and import external packages using a dependency manager called ‘Grape.’ . // This will get the spring-orm package from mvnrepository.com (maven) @Grab(group=’org.springframework’, module=’sprint-orm’, version=’5.2.4.RELEASE’) // this will then enable this class to be imported that doesn’t come as standard import org.springframework.jdbc.core.JdbcTemplate . Documentation is available at grape-docs . More information about the maven repo at maven . Note, @grab does not work in pipeline scripts. Instead, you need to install a plugin that provides functions you want. ",
    "url": "/groovy/#external-packages-grape",
    "relUrl": "/groovy/#external-packages-grape"
  },"31": {
    "doc": "Groovy",
    "title": "References",
    "content": ". | groovy-download | groovy-sh | groovy-docs-semantics | groovy-docs-semantics-optional-keyword | groovy-docs-oop | groovy-docs-dev-kit | groovy-docs-structure | grape-docs | maven | pluralsight-groovy-fundamentals | . ",
    "url": "/groovy/#references",
    "relUrl": "/groovy/#references"
  },"32": {
    "doc": "Jekyll",
    "title": "Jekyll",
    "content": ". | Basics | Themes | | References | . I’ve been looking for a static site generator for a while. And at some point even wrote my own. However, because I don’t want to maintain my own, I want to use someone elses. I am looking for a few things: . | static site generation so the site can be hosted on github pages | generated from source so changes to the site can be stored in git | quicky and easy | looks decent | site generated from markdown | . HTML is a hateful markup language for humans to write. You need something on top of it to achieve some level of sanity. Markdown is a nice simple markup language. And I am pretty happy writing text files and then using markdown. Thus, I want a site-generator that converts markdown to fairly decent, lightweight HTML. Without any crazy backends like PHP dynamically generating the site from a database. That sounds so awful. ",
    "url": "/jekyll/",
    "relUrl": "/jekyll/"
  },"33": {
    "doc": "Jekyll",
    "title": "Basics",
    "content": "Jekyll is written in ruby. Visit https://jekyllrb.com/. Jekyll documentation pretty clearly warns you against using it on Windows. That’s probably because Ruby is really a linux commnuity and so they only think about Windows after-the-fact. Thus, if your on Windows, use Windows linux subsystem, and install ruby there. Please know a fair amount of what follows if just copy-pasted from other sites so I don’t have to go fishing for those places. Credits are in the Reference section. sudo apt-get install ruby-full build-essential zlib1g-dev # Avoid installing gems in system ruby echo '# Install Ruby Gems to ~/gems' &gt;&gt; ~/.bashrc echo 'export GEM_HOME=\"$HOME/gems\"' &gt;&gt; ~/.bashrc echo 'export PATH=\"$HOME/gems/bin:$PATH\"' &gt;&gt; ~/.bashrc source ~/.bashrc # Install jekyll gem install jekyll bundler # Create a new site at /blog dir jekyll new myblog cd myblog # Server the site. The site auto-refreshes. bundle exec jekyll serve . I think the rest is fantastically straight-forward to be honest. Once you have tried it a little bit at first. ",
    "url": "/jekyll/#basics",
    "relUrl": "/jekyll/#basics"
  },"34": {
    "doc": "Jekyll",
    "title": "Themes",
    "content": "You’ll see a remarkedly small amount of ‘source’ files in your site folder. This is because the default shipped theme ‘minima’ is actually installed as a ruby gem. The _posts directory is were your blog posts appear. Then there is a _config.yml that does some site-wide configuration, including selecting the theme. And there is an index/about page in markdown. This is super small. Then, when you invoke bundle exec jekyll serve it a _site directory that has all this HTML and stuff. Where does this come from? Well it comes from the ruby gems you installed, jekyll and the default theme. Pretty neat. How then do you change the theme or view where the files for the minima theme are? The minima theme is a gem, so actually you can see where on the file system it’s installed with ` bundle info –path minima`. But, obviously editing the package directly isn’t the supported way to alter or customise the theme. However, I don’t particularly want to use the minima theme. I decided to use another one that was good for documentation. In particular, I went for a theme called just-the-docs. Install it with gem install just-the-docs then set the _config.yml theme to theme: \"just-the-docs\". And bingo. ",
    "url": "/jekyll/#themes",
    "relUrl": "/jekyll/#themes"
  },"35": {
    "doc": "Jekyll",
    "title": "Table of contents",
    "content": "The ‘just-the-docs’ theme looks like it has a lot of the basic functionality I would like. But I would also really quite like a Table of Content that is present in a manner like the theme Mkdocs-Jekyll. It is based on Google’s material theme. But it has a nice table of contents that sits on right hand side of the page. But before worrying about placing it on the right-side, how do I get a table of contents at all? I want an auto-generated table of contents. This seems kind of crazy but literally insert the following into the page where you want to TOC to appear . * TOC {:toc} . It seems important to have the * ... line present before the toc command. I have no idea why. I really have no idea. This blog post seems to describe it in more detail https://blog.webjeda.com/jekyll-toc/. As does this page https://ouyi.github.io/post/2017/12/31/jekyll-table-of-contents.html. And perhaps once you finally get a TOC inserted, you can look at kramdowns page on what you can do with toc. https://kramdown.gettalong.org/converter/html.html . ",
    "url": "/jekyll/#table-of-contents",
    "relUrl": "/jekyll/#table-of-contents"
  },"36": {
    "doc": "Jekyll",
    "title": "References",
    "content": ". | https://jekyllrb.com/docs/installation/ubuntu/ | https://pmarsceill.github.io/just-the-docs/ | https://blog.webjeda.com/jekyll-toc/ | . ",
    "url": "/jekyll/#references",
    "relUrl": "/jekyll/#references"
  },"37": {
    "doc": "Jenkins and Groovy",
    "title": "Jenkins and Groovy",
    "content": ". | Basics | Creating a test job for jenkinsfile code | References | . ",
    "url": "/jenkins-and-groovy/",
    "relUrl": "/jenkins-and-groovy/"
  },"38": {
    "doc": "Jenkins and Groovy",
    "title": "Basics",
    "content": "I can recommend this course as pretty good: pluralsight-automating-jenkins-groovy. Jenkins works with a plug-in model. Applications that conform to the plug-in standard. Groovy support is implemented as a plugin. When we install and enable the groovy plugin, we get two extra build steps, groovy script and groovy system script. When we’re running groovy inside Jenkins, we get a few extra default imports: . import jenkins.* import Jenkins.model.Jenkins import hudson.* import Hudson.model.* . The formal documentation for the Jenkins api is available at javadoc-jenkins-ci . You can run groovy scripts to configure Jenkins when it starts by placing groovy files in a folder init.groovy.d. These scripts are run alphabetically, and can be used to dynamically configure Jenkins on start-up. There is this very important thing at http://&lt;jenkinsurl&gt;/pipeline-syntax . There’s also the general documentation here jenkins-book-pipeline . And it seems the following page is a reference of steps jenkins-book-pipeline-steps . ",
    "url": "/jenkins-and-groovy/#basics",
    "relUrl": "/jenkins-and-groovy/#basics"
  },"39": {
    "doc": "Jenkins and Groovy",
    "title": "Creating a test job for jenkinsfile code",
    "content": "If you want to try out a Jenkinsfile on a local Jenkins, without using source-control, just to check whether the jenkinsfile will even run, you can create a Jenkins job . Go to Jenkins front-page, then ‘new-item’, then select ‘pipeline’ and an item name like ‘tempjob’. Then in the job configuration, there’s a pipeline section. With ‘Pipeline script’ as the definition, you can paste in the contents of a Jenkinsfile and run the job, to see what happens. ",
    "url": "/jenkins-and-groovy/#creating-a-test-job-for-jenkinsfile-code",
    "relUrl": "/jenkins-and-groovy/#creating-a-test-job-for-jenkinsfile-code"
  },"40": {
    "doc": "Jenkins and Groovy",
    "title": "References",
    "content": ". | javadoc-jenkins-ci | jenkins-book-pipeline | jenkins-book-pipeline-steps | pluralsight-automating-jenkins-groovy | . ",
    "url": "/jenkins-and-groovy/#references",
    "relUrl": "/jenkins-and-groovy/#references"
  },"41": {
    "doc": "Powershell",
    "title": "Powershell",
    "content": ". | Get the type of something | Type literals | Arrays | Hashtables (dictionaries) | Create your own new object . | Copy an object | Compare Object | . | Enumerations | Parameters | Splatting | Copying files and folders | Find files in a directory | Get event logs from the system! | Grep for lines in a text file | Get the date! | Mark as script as admin only | Create an background job | Debugging . | Tracing/Capturing session output with a transcript | . | Error behaviour . | Terminating errors | Exception does not print line error occurred? | . | Catching an exception | Throwing exceptions | Remote commands | Create a transcript | Convert something to a bool | Delayed execution, lambda/anonomous functions | Function decorators | Reimporting a module | Find current file location’s | Scopes | Try to return last-exit code only from a function | Returning things from functions | The AST | POSH things that suck . | Namespaces | Out-string, tricky strings! | Conver between user names and ssids | Certicates | Conflicting powershell commands | Comparing nested objects | Write-host host console wtf? | Verbose perference | Classes | Catching errors with -erroraction | . | . Everything in powershell is an object. Which means it has a type. The typing system can be quite tricky because it’s dynamic. And also powershell will do a lot for you to try to help make things less verbose. Because powershell is a shell, (as well as a scripting language), it outputs all evaluations of expressions to stdout. This makes it different from say python, where you need to explicitly call a print statement. For powershell, this even applies inside functions. The return value of a function is more like a control-flow keyword. IF you store the output/return-value of a function, you’re actually going to get anything that was printed to stdout and not explicitly caught. Explicitly catching output going to the stdout from expression evalution is done by assigning it to a variable or dealing with the output in some other way. The other thing is that powershell runs on the .dotnet runtime and it’s very analogous to c#. So it’s apparently pretty easy to convert c# code into powershell and vice versa. The benefit of c# is that it’ll probably run faster than powershell code. There are a few types of source-code. Cmdlets . A command-let is something implementing by a .NET class that derives from the Cmdlet base-class in the powershell sdk. Building a cmdlet requires the powershell sdk, which is freely available. This category of command is compiled into a dynamic link library and then loaded into the powershell process. Basically corresponds to a built-in command. Though anyone can add and create their own. Functions . Created in memory and is discarded by the interpeter when it exits. There’s also something called a workflow. Scripts . Read from a .ps1 text file and then stored in memory. Native commands (applications) . These are just win32 executable that you can call, like choco.exe. They handle their own parameters and output. It also requires another process to load. Get the type of something . Types are useful to know what you’re working with. But, in a dynamic language, you tend to care what methods/properties are available and you care less about types, potentially. How to get the type: $object.GetType() . $hello = \"helloworld\" $hello.GetType() $hello.GetType().FullName . How to get the methods and properties: get-member . Becarefull using the get-member. get-member command returns the properties and methods on an object. Useful for discovering what can be accessed on an object. $hello = 'helloworld' # Find all the methods and properties available on the string $hello get-member -inputobject $hello . For a while, I thought you could pipe the variable to the get-member. Which seemed shorter that writing get-member -inputobject $hello. $hello = 'helloworld' $hello | get-member . However, this is pretty dangerous. Let’s say you have an object which is a list, and you want to find the members and properties on the list . $a = 1,2,3 $a | get-member &gt; TypeName: System.Int32 ... This actually has passed an element from the list a, which is an int, and told you the properties/methods on it. Interestingly, because the array is only made up of int, it only printed the methods/properties once rather than three times. If you make the list or collection with different types in the elements, then it seems to print each methods/properties for the different elements. $a = 1, 'abc', @{d=5} $a | get-member &gt; # prints methods/proprties for the int, string and hashtable. Nice. Type literals . Arrays . There actually isn’t a list literal syntax in powershell. In python you can write ‘a = [1,2,3]’, which assign the variable name a to the list of integers. In powershell, strangely, it doesn’t have something like this. But it does, of course, have arrays. Instead, you can do something like this with commands . $a = 1,2,3 . It’ll create the variable a, with the underlying type [object[]], which is a dotnet array. Apparently things in pipelines, since posh v3, will return arrays. This is because people writing pipeline code tend to expect to be working on a list of inputs, and so pipelines should default to returning lists of stuff even if there’s only one element in the array. E.g., this creates a list: . $out = get-childitem | where {$_.extension -eq '.json'} # the $out is an array, i.e. [object[]] $out.GetType().Fullname . Apparently, all objects have the .Count() method to behave in a puesdo-array type-way for the benefit of pipelines: . ”\"”Since PowerShell v3, any object is treated as a pseudo-array and has a Count property. This is to remove issues where pipelines could return one, or many, objects. The single object case would cause errors in code designed for a collection of many objects.””” from Powershell In Depth, Manning . Dangerous arrays . In python, if a points to a list, and then b points to a, b actually points to the list. This is the same in powershell. $a = 1,2,3 $b = $a write-host $b &gt; 1,2,3 . If you mutate the contents of $a, then $b changes too. $a[0] = 'one' write-host $b &gt; 'one',2,3 . But this doesn’t hold true in powershell if you reassigns using += or -=, ahh!! . $a = 1,2,3 $b = a $a += 4 write-host $a &gt; 1,2,3,4 write-host $b &gt; 1,2,3 . Ahhh! This is because when assignment happens, using +=, powershell copies the list $ points to, adds the new 4 and then points $a to the new list. It doesn’t actually mutate the underlying list. It creates a brand new once at a different memory location. Ahh!! This seems pretty dangerous. Or at least, likely to cause some bugs you haven’t thought about. Hmm…. Python doesn’t suffer this problem. Because it mutates the underlying list rather than copy and add on a new list. a = 1,2,3 b = a a[0] = 'one' assert b == a # true a += [4,] print a assert b == a # true . You can also creates arrays like this: . (, 1).length # though this is really evalute the expression ',1' first rather than a special array notation &gt; 1 @().length # rather than @{} curly-braces for hashtables, it makes sure whatever is return is always an array! &gt; 0 . Hashtables (dictionaries) . Beautiful hashtables are pretty easy to create and use . It begins with @{}, and uses newline to create next entry, where = is used to assign. $person = @{ firstname = 'donal' lastname = 'mee' age = 999 } # Though this could be truncated to: $person = @{firstname = 'donal'; lastname = 'mee'; age=999} . You can do the typical [] to look-up a key in the hashtable, and you can also use the dot property . $person['firstname'] $person.lastname # Interestingly, this just returns $Null and doesn't throw an error $person['doesntexit'] # And key looksup are also case-insenstive $person['FIRSTNAME'] . The weird thing perhas is that when you want to iterate over a hashtable, the is a bit unnatural. You must explicitly call GetEnumerate() in the for loop. Otherwise, the first and only value return is the entire hashtable itself. # Weirdness! # reusing person about foreach ($pair in $person) { $pair count ++ } &gt; # Just prints the entire hashtable write-host $count &gt; 1 # Must explicitly call the enumeration, lord knows why $count = 0 # reset count foreach ($pair in $person.GetEnumerate()) { $pair count ++ } &gt; prints each pair once write-host count &gt; 3 . There’s also something called an ordered hashtable. Hashtables don’t return their contents in the same order the pairs were placed into the hashtable (unsurprisingly). But you can get this behaviour using the ordered hashtable cast, which is quite cool (like pythons ordered dictionary) . $a = [ordered] @{ a = 1 b = 2 c = 3 } write-host $a[0] &gt; 1 write-host $a[1] &gt; 2 . If you want to extend an existing hashtable . $a = @{ a = 1 b = 2 } $a.Add(c, 3) . Create your own new object . Classes, in most programming languages, are the means to create new types of objects. However, Powershell seems to be particularly relaxed about the idea of classes. Classes were only introduced in version 5 of the language. The keyword ‘class’ had been reserved for 10 years before this. It took them this long to get around to creating classes! Which is partly because they wanted to do it write and partly because Powershell is happy for users to create objects dynamically. It seems that in particular, the most useful is . $mything = New-Object PSObject -Property @{ Name = 'Adam' Age = 28 } $mything.Name $mything.Age . Extending existing objects . You can also add or extend a property. Using the Add-Member commandlet. # Create two new objects $two = New-Object psobject $two | Add-Member -MemberType NoteProperty -Name even -Value $true $three = New-Object psobject $three | Add-Member -MemberType NoteProperty -Name even -Value $false # Group the objects by whether the even property is true $two, $three | group-object -Property even . Be VERY careful with Add-Member. I had initally, and painful tried this for a while. And OMG, it appears that I didn’t quite correct a property on the objects even though it seems like I sort of had… . # Create two new objects $two = New-Object psobject $two | Add-Member -NotePropertyName even -NotePropertyValue $true $three = New-Object psobject $three | Add-Member -NotePropertyName even -NotePropertyValue $false # Group the objects by whether the even property is true $two, $three | group-object -Property even ` . HANG on. That worked! Wtf… There must be something else going on… . Copy an object . You can also copy you own custom objects and potentially other objects. Let’s say you write a function that needs to temporarily mutate the object is it passed. And you don’t want to really mutate the original object. function Nasty-Mutator ($thing) { $thing.symbol = 'Mutated!' write-host \"The thing now is: $thing\" } $demon = New-Object -typename psobject -property @{ name = 'donal'; symbol=666} Nasty-Mutator -thing $demon $demon function No-Mutations ($thing) { $thing = $thing.psobject.copy() $thing.symbol = \"make me a princess!\" write-host \"The thing now is: $thing\" } $frog = New-Object -typename psobject -property @{ name = 'princess'; symbol=7} No-Mutations -thing $frog $frog . Compare Object . Comparing objects in powershell can be a right pain. Largely because it’s hard to know what’s it default comparison operator is between objects and it doesn’t encourage types, so it’s not like you can rely upon controlling comparsion by type. Let’s say you have a complicated type that is your own custom powershell object. Just comparing the two of them, even if they seem to be the same, will produce False. $thing1 = [PSOBject]@{a='hello'; b='world'} $thing2 = [PSOBject]@{a='hello'; b='world'} $thing1 -eq $thing2 &gt;&gt;False . Note just how sad this is! In fact, this is sort of like python. If we compared just a straight hashtable rather than via a psobject, then the comparison would be fine. Hang on! That’s actually not correct. Comparing two hashtables that are the same still produces False. Wtf. $thing1 = [PSOBject]@{a='hello'; b='world'} $thing2 = [PSOBject]@{a='hello'; b='world'} $thing1 -eq $thing2 &gt;&gt;False . We can use the explicit Compare-Object, but even it seems to suck balls for hashtables! It doesn’t seem to be able to handle comparing keys and values at the same time… . There is the Compare-Object which seems to work…. for something like a PSObject . $x = [PSOBject]@{a='hello'; b='world'} $y = [PSOBject]@{a='hello'; b='world'} Compare-Object $x $y . Enumerations . In powershell v5, enumerations were added. Before that, posh users had to create enumerations using c#. For background, see these two articles: . | https://devblogs.microsoft.com/scripting/working-with-enums-in-powershell-5/ | https://devblogs.microsoft.com/scripting/new-powershell-5-feature-enumerations/ | . An enumeration can now be created like: . Enum Stuff { Apple = 10 Bear = 33 David = 666 } . The weird thing is that it’s a bit hard to get the values of the enumeration. Anyway, Stuff becomes a new type. [Stuff] [Stuff]::Apple [Stuff]::Bear . The weird thing is each enumeration has a value__ property. Yes that really is a double underscore. Fuck me! Why did powershell do that? I have no idea. [Stuff]:Apple.value__ # will print 10 . To iterate over the enumeration, you need to use a method on [Enum] type. # or could write [enum]::GetValues([type]$enum) ForEach ($thing in [enum]::GetValue([Stuff])) { $thing, $thing.value__ } . So let’s say you want to find all the things in a particular enumeration, say the powerpoint file type enumeration . # Might first have to import the assembly, or have it done for you like # $ppt = New-Object -ComObject 'Powerpoint.Application' $enum = [Enum][Microsoft.Office.Interop.Powerpoint.PpSaveAsFileType] $pptStuff = @{} ForEach ($_e in [enum]::getvalue($enum)) { $pptStuff.Add($_e, $_e.value__) } $pptStuff . Parameters . # At the top of a script, or function, place Param( [Parameter(Mandatory=$true, Position=0, HelpMessage=\"First param called first\")] $First, # comma between parameters, params are capital case by convention [Parameter(HelpMessage=\"Second Param has a default value\")] $Second = \"myDefault\", [switch]$Flag, # switch parameter ) . Parameters are pretty interesting in powershell. There is something in the interpreter called the parameter binder. This is responsible for converting parameters (names of arguments) and arguments (the value itself) into a sensible type. Powershell is pretty generous. The parameter binder will try to convert values to required values. Etc. Splatting . Splatting is a nice way to feed params to a command. It’s like pythons unpacking hello(*pass). Let’s say there is a command I call in the same place with the same options. I don’t want to repeat those arguments each time, or at least, manually. # create an array of the options # we could use a hash table to do keywords $gitOptions = \"git\", \"--params\", \"/GitOnlyOnPath /NoGitLfs /SChannel /NoShellIntegration\" # and then we unpack, we goes in the order unpacked choco install -y @gitOptions . Copying files and folders . Perhaps you want to copy the contents of a directory into the current directory. This will copy all the contents of the remote directory into the current directory. The -recurse is pretty important, otherwise, you’ll get just the top level of the files. The next handy feature is the star. Without the star, you get the contents of the ‘copy’ directory as a new directory in the current working directory. # get-alias -name cp # get-alias -definition copy-item copy-item the\\folder\\to\\copy\\* -recurse . Find files in a directory . It’s pretty typical that you’ll have a directory, and you want to look for a particular file. Perhaps you want to find just the json files. # the -file parameter means don't consider directories to be items themselves, which isn't strictly necessary get-childitem -recurse -path \\folder\\to\\search\\ -filter \".json\" -File . While filter is efficient, it isn’t that flexible (other than wildcards), because it’s limited to filtering on 1 critera. But perhaps you want to filter off and .log, .png, and .txt files, and then get whatever is left. Welcome the where-object command, which is like select-string except it drops any object that doesn’t match the criteria. # get-alias -definition get-childitem -&gt; ls # get-alias -definition where-object -&gt; where, ? # this command says get every file within the search folder, and then drop any files with extensions .json or .png or .log get-childitem -recurse -file -path \\folder\\to\\search | where-object {$_.extension -NotIn \".json\", \".png\", \".log\"} # equivalent to this ls -recurse -file -path \\folder\\to\\search | ? {$_.extension -NotIn \".json\", \".png\", \".log\"} . Get event logs from the system! . | Creating a boottime when the machine started today | Then getting all the error logs | . $boottime = get-date -year 2019 -month 3 -day 12 -hour 09 -minute 44 get-eventlog -logname system -after -entrytype Error . | This prints a summary of the log information. But we might want to see everything. Do this: | . get-eventlog -logname system -after -entrytype Error | Select-Object -Property * . Grep for lines in a text file . Or perhaps your trying to select lines with particular string? This prints out all lines with ‘success’. get-content $filename | select-string \"success\" # The alias for select-string is 'sls' . The select-string actually has some quite nice in-built functionality to search across directories or files. You can combine this: . # Look through all the files in logfiles directory, drop any files not ending in .log, get the contents of the file # and then search the contents for 'success' get-childitem \\path\\to\\logfiles | where-object {$_.extension -eq \".log\"} | get-content | select-string \"success\" . In just one call . select-string -path \\path\\to\\logfiles*.log -pattern \"success\" . Get the date! . This prints the date now, which I think using some system type . $([DateTime]::Now) . But there is a whole powershell commandlet for it . # prints date &amp; time in a timestamp format, though not suitable for filenames Get-Date -Format o # custom one for filenames Get-Date -UFormat \"%Y-%m-%d_%Hh%Mm%Ssec\" . Mark as script as admin only . Quite a few scripts will require administrator privileges to be effective. Powershell provides a way to mark a script as needing higher privileges. You can use this directive. It a lot of ways it looks like a comment, but it isn’t without an effective. Put it at the top of the script. #Requires -RunAsAdministrator . Create an background job . | Creating a background job to cp test result into investigating dir. Note, I’ve already set $invest | Start-Job pwd is not the cwd. It’s cwd is in your Documents folder for some reason. | . Start-Job -ScriptBlock {cp -recurse \\\\&lt;filepath&gt; $invest} # This will get information about status of the background job Get-Job -Id 1 . | ExpertT also suggested trying asychronous cp alternative get-command -noun bitstransfer | . Debugging . Commands: . | Enter-PSHost . | This allows you to grab other powershell process and begin debugging them. You cannot debug the process this is invoked in. It is only for other powershell processes. Not the current one. | . | Debug-Runspace . | Not sure what this does. But I think that multiple powershell processes can be hosted in a single runspace, or something. Again, you can’t debug the ‘default’ or current runspace which you can find through “$ExecutionContext.Host.Runspace”. | . | Set-PSDebug -Trace 1 . | Doesn’t start an interactve debugger but does trace every call. Which is very useful. | . | Set-PSDebug -Step . | This is the normal stepwise debugger! Yes! | . | . To stop the debugger type . | Set-PSDebug -off | . This will trace how the parameters are bound in the expression. Parameter binding in powershell is quite complicated. Trace-Command -Name ParameterBinding -Option All -Expression { 123 | Write-Output } -PSHost . Actually this article perhaps is most useful, if you want to run the code and then let it hit the exception. You can use Set-PSBreakPoint to set a line on a script that will trigger the debugger. Set-PSBreakpoint -Script .\\wake-on-lan.ps1 -Line 64 # then just run the script .\\wake-on-lan.ps1 # and at line 64 the debugger will open, use ? or h to get the help for the debugger. Tracing/Capturing session output with a transcript . Sometimes, especially with remote machines and when you’re calling powershell through some third party like ruby, you want a way to record what the is happening when you run a script and you want to store all the output you see at the console. You can use Start-Transcript and Stop-Transcript and point the transcript to a file, like Start-Transcript -Path 'posh.log' . Error behaviour . The default behaviour of powershell - unlike python - is to continue if it hits an error. This is actually somewhat sane given it’s a system admin shell. The sensitivity of python to exceptions can make it fiddly and certainly more likely to stop doing work that could be useful. However, Powershell provides the user with a way to control the error behaviour by setting a session variable called the ErrorActionPerference. The variable determines whether to treat unhandled errors as terminating or non-terminating errors. $ErrorActionPreference = \"Stop\" # Or one of 'Continue', 'SilentlyContinue', 'Stop', 'Inquire', 'Suspend' . Terminating errors . Terminating errors are very important and a potential trip-up. Just because something appears to write an error does not mean it is a terminating error. A terminating error in powershell is one that will throw an unhandled exception and will stop your program unless it’s caught by a try catch. However, most?/many errors in powershell are non-terminating by default. For good reason, because powershell wants your code to do as much work as possible. However, observe: . C:\\dev\\repo [donal_branch ≡ +2 ~0 -0 !]&gt; Import-Module 'DOES NOT EXIST' Import-Module : The specified module 'DOES NOT EXIST' was not loaded because no valid module file was found in any module directory. At line:1 char:1 + Import-Module 'DOES NOT EXIST' + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : ResourceUnavailable: (DOES NOT EXIST:String) [Import-Module], FileNotFoundException + FullyQualifiedErrorId : Modules_ModuleNotFound,Microsoft.PowerShell.Commands.ImportModuleCommand C:\\dev\\repo [donal_branch ≡ +2 ~0 -0 !]&gt; try { Import-Module 'DOES NOT EXIST'} catch { write-host 'Hello from the catch' } Import-Module : The specified module 'DOES NOT EXIST' was not loaded because no valid module file was found in any module directory. At line:1 char:7 + try { Import-Module 'DOES NOT EXIST'} catch { write-host 'Hello from ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : ResourceUnavailable: (DOES NOT EXIST:String) [Import-Module], FileNotFoundException + FullyQualifiedErrorId : Modules_ModuleNotFound,Microsoft.PowerShell.Commands.ImportModuleCommand C:\\dev\\repo [donal_branch ≡ +2 ~0 -0 !]&gt; try { 1/0 } catch { write-host 'Hello from the catch' } Hello from the catch C:\\dev\\repo [donal_branch ≡ +2 ~0 -0 !]&gt; $error[0] Attempted to divide by zero. At line:1 char:7 + try { 1/0 } catch { write-host 'Hello from the catch' } + ~~~ + CategoryInfo : NotSpecified: (:) [], RuntimeException + FullyQualifiedErrorId : RuntimeException C:\\dev\\repo [donal_branch ≡ +2 ~0 -0 !]&gt; $error[1] Import-Module : The specified module 'DOES NOT EXIST' was not loaded because no valid module file was found in any module directory. At line:1 char:7 + try { Import-Module 'DOES NOT EXIST'} catch { write-host 'Hello from ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : ResourceUnavailable: (DOES NOT EXIST:String) [Import-Module], FileNotFoundException + FullyQualifiedErrorId : Modules_ModuleNotFound,Microsoft.PowerShell.Commands.ImportModuleCommand C:\\dev\\repo [donal_branch ≡ +2 ~0 -0 !]&gt; try { Import-Module 'DOES NOT EXIST' -ErrorAction stop } catch { write-host 'Hello from the catch' } Hello from the catch C:\\dev\\repo [donal_branch ≡ +2 ~0 -0 !]&gt; $error[0] Import-Module : The specified module 'DOES NOT EXIST' was not loaded because no valid module file was found in any module directory. At line:1 char:7 + try { Import-Module 'DOES NOT EXIST' -ErrorAction stop } catch { writ ... + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : ResourceUnavailable: (DOES NOT EXIST:String) [Import-Module], FileNotFoundException + FullyQualifiedErrorId : Modules_ModuleNotFound,Microsoft.PowerShell.Commands.ImportModuleCommand . Note, the importance of this: . | Just because an error occurs inside a try/catch does not mean it’s always going to trigger the catch | Some types of errors default to be terminating (i.e. divide by zero) | Other types of errors default to be non-terminating (like the import-module) | For cmdlets, you can use the -ErrorAction to make a non-terminating error terminating | . There is an discussion about this online at https://github.com/MicrosoftDocs/Powershell-Docs/issues/1583 . Exception does not print line error occurred? . My shell, I put in: . function Badness { param ( [Parameter(Mandatory=$true)] $Url ) Nested -Url $Url } function Nested { param($Url) Invoke-RestMethod -Url $Url } Badness -Url 'www.google.com' . ExpertT’s shell showed, and he said “the error stack is very nice because even if something deep down a call emits an error, it’ll be in the error stack which means you don’t necessarily have to redo the erroring operation with a debugger or add logging a snippet of the error record automatically rendered in my shell:” . (109)C:\\dev\\repo&gt; Badness -Url 'www.google.com' Invoke-RestMethod : A parameter cannot be found that matches parameter name 'Url'. At line:10 char:23 . …Which is what you wanted to see? and the error record has the useful invocationinfo property as we explored earlier also another property: . &gt; $e.ScriptStackTrace at Nested, &lt;No file&gt;: line 10 at Badness, &lt;No file&gt;: line 6 at &lt;ScriptBlock&gt;, &lt;No file&gt;: line 1 . …Which is useful too inside the errorrecord object is also the exception…(object, OF COURSE): ExpertT: an interesting property on that . &gt;$e.Exception.targetsite Name : VerifyArgumentsProcessed DeclaringType : System.Management.Automation.CmdletParameterBinderController ReflectedType : System.Management.Automation.CmdletParameterBinderController MemberType : Method MetadataToken : 100671752 Module : System.Management.Automation.dll ... ## snipped . …which looks like it is showing the parameter binding exception”. Donal said “That isn’t what my shell shows. It shows:” . C:\\Users\\donal.mee&gt; Badness -Url 'www.google.com' Badness : A parameter cannot be found that matches parameter name 'Url'. At line:1 char:1 + Badness -Url 'www.google.com' + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ + CategoryInfo : InvalidArgument: (:) [Badness], ParameterBindingException + FullyQualifiedErrorId : NamedParameterNotFound,Badness . ExpertT says “I suspect you have $ErrorActionPreference=’stop’ which is not a canonical way to drive the pipeline so I recommend you set it to Continue the idea is usually to drive a pipeline as much as you can, then collect errorrecords and decide if you want to retry or not or do something alternative the idea isn’t usually to panic and stop. the difference between ‘ignore’ and ‘silentlycontinue’ is whether an errorrecord is popped onto the error stack. You will find that the type of object you get back off the errorstack differs when erroractionpreference=’stop’. System.Management.Automation.CmdletInvocationException  vs  System.Management.Automation.ErrorRecord” . Catching an exception . When powershell writes an error to stdout, it often gives it name that you can’t then catch. What? I must not understand something about powershell exceptions. For example, ls a directory that doesn’t exist. C:\\dev\\infra [master ↑3 +0 ~4 -1 | +10 ~3 -0 !]&gt; ls __init__.pycas ls : Cannot find path 'C:\\dev\\infra\\__init__.pycas' because it does not exist. At line:2 char:1 + ls .\\__init__.pycas + ~~~~~~~~~~~~~~~~~~~ + CategoryInfo : ObjectNotFound: (C:\\dev\\infra\\__init__.pycas:String) [Get-ChildItem], ItemNotFoundException + FullyQualifiedErrorId : PathNotFound,Microsoft.PowerShell.Commands.GetChildItemCommand . You’d think you could catch this with something like this . try { ls .\\__init__.pycas } catch [Microsoft.PowerShell.Commands.GetChildItemCommand] { write-host \"caught!\" } . Alas not! The ErrorID is not the thing to catch. Not is [ItemNotFound] or anything else in the stdout. Ahh! . However, there is a way to discover the error type to catch and the error type to catch is suprising. try { ls .\\__init__.pycas } catch { $_.exception.gettype().fullname } . Which will print System.Management.Automation.ItemNotFoundException. WTF! Yeah. So to catch this you’d write . There’s also the error exception stack. Which has the last errors on the stack. &gt;$e = $error[0] # get the most error &gt;$e.Exception.GetType().fullname System.Management.Automation.ItemNotFoundException . try { ls .\\__init__.pycas } catch [System.Management.Automation.ItemNotFoundException] { write-host \"finally caught!\" } . Note! Just because something is in the $error stack it does not mean it was a terminating error and you writing try/catch will not neccessarily catch it. See above on terminating errors. Throwing exceptions . Perhaps you want to throw an exception. Why wouldn’t you? This is were the throw keyword comes in. Let’s say I have been writing a function, but it’s not finished. And I’d like to throw an error if the user tries to call it. function Do-Plumbing() { # We all know Plumbers never finish their work. throw [System.NotImplementedException] } . Interesting, the throw can throw any object, like a user message or a string. Lolcats. Yes indeed. function Call-Plumber() { # We all know plumbers don't answer their phones either throw \"This is Dave. I'm not available now. Leave a message.\" } . And, like in Powershell, there is a Command-let for everything. There is the Write-Error commandlet. But this just writes to the stderr. It does not generate a terminating error. write-error 'Well, if you hit an error, why would you want to stop?' . Remote commands . There is a pretty detailed PS doc section here . | Tutorial on remoting | Overview of remoting | . Needs to be enabled on the remote machine first, and you also need to enable remoting on the client. Enable-PSRemoting -Force # There is also the older but I guess almost equivalent winrm quickconfig # This should set the WinRM service to run and enable relevant firewall rules Get-NetFirewallRule -Name *winrm* . Please note that Powershell Remoting is a complicated topic. But WinRM is one of the transport layers that Posh remoting can work over. There are a bunch of others, including SSH. This works provided your on the same AD domain. Otherwise, you’ll need to specify some trusted machines that are allowed to connect. See here . There are quite a number of settings. On the client machine, the relevant area is in . ls wsman:localhost\\client # We can very generously set all possible hosts as trusted. Set-Item wsman:localhost\\client\\TrustedHosts * # Also the relevant authenication methods that are allowed by the client are, set the ones you care about to true ls wsman:localhost\\client\\auth . | Test the connection to the server: | . Test-WsMan &lt;COMPUTERNAME&gt; . You may find it’s hard to connect to the computer. This is normally a networking issue. Check whether the machine is on the domain and whether the full-qualified domain host (FQDN) is resolvable. If it is not resolvable, then you can’t use that name to connect to the machine. Instead, you’ll need to use the IP address. Some of the authencation options, like CredSsp, don’t seem to work well with IP addresses. Thus try using default authentication . $tbhr = Get-Credential -UserName &lt;username&gt; -Message 'Connecting to machine' # Also, note user is an admin on the machine, then you can probably use that account to connect. However, what users are allowed to connect to a machine via RDP is a configurable property. $donzer = New-PSSession -Credential $tbhr -Authentication default -ComputerName 10.14.2.213 Invoke-Command -Session $donzer -ScriptBlock { dir \\ } . How to check whether a name is resolvable? nbtstat loops through . nbtstat -a machinex.test.corpb.local . There are also some powershell commands . &gt; Resolve-DnsName vmaas-466265 Name Type TTL Section IPAddress ---- ---- --- ------- --------- vmaas-466265.corpb.net A 0 Answer 92.242.132.24 &gt; Resolve-DnsName vmaas-466265.test.corpb.local Name Type TTL Section IPAddress ---- ---- --- ------- --------- vmaas-466265.test.corpb.local A 1200 Answer 10.14.2.213 &gt; Resolve-DnsName vmaas-466265 Name Type TTL Section IPAddress ---- ---- --- ------- --------- vmaas-466265.corpb.net A 0 Answer 92.242.132.24 # Note! The 92.242.132.24 are misleading responses. Use nslookup to check the domain. # It is barefruit.co.uk which VirginMedia uses to serve a page of search results as this is effectively # a DNS miss. Pretty annoying! . A powershell command a bit like ping or traceroute is Test-NetConnection. Note quite a lot of networks don’t allow pings so traceroute can suffer from these black holes :-( . &gt;Test-NetConnection vmaas-466265.test.corpb.local &gt;tracert.exe \"vmaas-466265.test.corpb.local\" . Netstat is also a super useful command that will display what TCP/IP ports are active on your machine . | Invoke a single command | . Invoke-Command -ComputerName COMPUTER -ScriptBlock { COMMAND } -credential USERNAME . | Enter a remote session | . Enter-PSSession -ComputerName COMPUTER -Credential USER . Create a transcript . You can create a transcript of everything that is typed and output to a powershell script using Start-Transcript. It outputs a timestamped file into your documents. Call Stop-Transcript to end. Convert something to a bool . The [boolean] placed in front of stuff does a good job of truthy conversion. function _chocoInstalled($package) { return ![boolean](choco info $package --local-only | Where {$_ -match \"0 packages installed\"}) } . Delayed execution, lambda/anonomous functions . The excellent {} syntax provides a way to have a callable bit of code that is later executed. $vmaasInstallation = {Test-Path \"C:\\Program Files (x86)\\Git\\cmd\\git.exe\"} &amp; $vmaasInstallation . Function decorators . Basic syntax for writing a decorator . function test { iwr google.com } rename-item function:\\test wrapped-test function test { write-host \"wrapping test\"; wrapped-test } . Writing a cache using a decorator that does some memoisation. function get-url($url) { iwr $url } rename-item function:\\get-url wrapped-get-url $_RESULT = @{} function get-url($url) { if (-not $_RESULT[$url]) { write-host \"$url not in cache\" $_RESULT[$url] = wrapped-get-url -url $url } else { write-host \"$url in cache\" } $_RESULT[$url] } . I had originally wanted “Does powershell have a memoisation decorator type function like python’s lru_cache? I have IO bound file query thing that would be nice to use something like lru_cache for. Otherwise, I’m going to use a global dictionary” . Reimporting a module . Debugging a module you’ll often have to reload it. Use -force . Import-Module tooDebug.ps1 # do debuging, edit file, save and wish to reload it Import-Module tooDebug.ps1 -force . Find current file location’s . In general, a stack overflow suggested inspecting the help about automatic variables: . get-help about_Automatic_Variables -full . However, to answer the question, Powershell equivalent of python’s file is: . $__file__ = $MyInvocation.MyCommand.Definition # Can get the directory like $__dir__ = Split-Path $__file__ . Though the name I’ve given it, with double-duners makes me wonder whether powershell enforces public/private names with underscores? . Scopes . @' &gt;&gt; function lfunc { $x = 100; $script:x = 10; \"lfunc: x = $x\"} &gt;&gt; lfunc &gt;&gt; \"my-script:x = $x\" &gt;&gt; \"global:x = ${global:x}\" &gt;&gt; '@ &gt; myscript.ps1 . There’s a global scope that can be accessed using “$global:” the colon is important. Then there is a script scope in scripts “$script:”. Try to return last-exit code only from a function . In python, when we return something from a function, we need to be explicit and use ‘return’ otherwise the function will return None. However, in powershell, it implicitly returns things from the function. This is because powershell is a shell, it doesn’t return results - it writes output or emits objects. This makes some difference! . For example, this code is trying to determine whether the linter passed or failed . function Lint-Bem { [CmdletBinding()] Param( [Parameter(Mandatory=$True, HelpMessage=\"Select a Linter\")] [ValidateSet('pylint', 'flake8')] [string]$Linter ) # Note Linter directly maps to the name of the test within selftests # but cannot add .py to the end, otherwise test-discovery fails. python $_run_script \"py.selftests.test_$Linter\" if ($LastExitCode -eq 0) { write-host \"last-exit code is $LastExitCode\" return $True } else { write-host \"last-exit code is $LastExitCode\" return $False } } function Lint-Interactive { Param( [string]$Linter ) $resp = Read-Host \"Run ${Linter}? Y/N\" # User may want to skip a linter if ($resp -match \"y\") { $result = Lint-Bem $Linter if (-not $result) { # It the linting fails $resp = Read-Host \"$Linter linting failed. Ignore? Y/N\" if ($resp -match \"n\") { # User cares that the linter has failed, exit 1 Write-host \"Stopping linting. Exit 1\" exit 1 } # else use is ignoring faiure and continuing } else { write-host \"result is $result\" } # else linter passed } # else user is skipping this linter } . The problem is that even if the $LastExitCode in Lint-Bem is not zero, the ‘if (-not $result)’ does not resolve to True and so the user is never asked whether the want to ignore the failed result. Ahh! . It’s because the $result is actually filled with all the objects written to the output and not use a boolean. Ahh! . It looks like this: . last-exit code is 1 result is C:\\dev\\repo\\tests\\py\\log.py:7:1: E302 expected 2 blank lines, found 1 C:\\dev\\repo\\tests\\py\\log.py:38:43: F823 local variable 'proc' (defined in enclosing scope on line 19) referenced before assignment C:\\dev\\repo\\tests\\py\\log.py:58:16: F821 undefined name 'connect' C:\\dev\\repo\\tests\\py\\log.py:59:27: F821 undefined name 'connect' 2019-04-16 12:00:30,256 ERROR [plugins:addFailure:59] Test failure for py.selftests.test_flake8.Flake8Tests.test_flake8 2019-04-16 12:00:30,266 INFO [run:main:138] Exiting with True False . Returning things from functions . Perhaps you want to return a custom object. That’s very useful. Let’s say we have matched upon a URL, and extract some useful information about the object. Like in python, we can return a tuple of stuff. But that’s not as useful as returning a nicely structured object. For example, . &lt;# .SYNOPSIS Useful for providing a jenkins URL and getting back useful information extracted from the URL. Meant as a helper function. #&gt; function Match-JenkinsJobUrl { Param( [Parameter(HelpMessage=\"Jenkins URL to extract a job and number from. Does not currently handle urls without a jobname and build number in them.\", Mandatory=$true)] [string] $Url ) # expecting URl to be something like https://jenkins.uk.corpb.net/job/cam_Component_Tests_On_Vmaas/3097/console # or perhaps https://jenkins.uk.corpb.net/job/cam_Component_Tests_On_Vmaas/3097/ $Url -match \"(.*corpb\\.net\\/)job\\/(\\w+)\\/(\\d*)\" | out-null if ($matches) { $hostname = $matches[1] $Jobname = $matches[2] $BuildNumber = $matches[3] return New-Object PSObject -Property @{ Url = $Url Hostname = $hostname Job = $Jobname JobUrl = \"${hostname}job/${Jobname}\" Build = $BuildNumber BuildUrl = $matches[0] } } else { # don't actually prnt the url, use escape of $ variable expansion with '' throw '$url does not match regex.' } } . The useful command here is the ++New-Object++ command. ",
    "url": "/powershell/",
    "relUrl": "/powershell/"
  },"42": {
    "doc": "Powershell",
    "title": "The AST",
    "content": "Powershell really opens the interpreter to you. The AST is available to you. Letting you do meta programming stuff. For example, the peskiness of erroaction means you need to check whether a command may at some point use ‘throw’ because other -erroraction is insufficent to continue if there’s an error. Lets write a function that at least checks whether any commands written in posh contain a throw. Lets look at the AST . filter test-throws { if (-not $_.scriptblock) { write-warning \"no script found for $_\" return } else { [bool]$_.Scriptblock.ast.findall({$args[0] -is [System.Management.Automation.Language.ThrowStatementAst]}, $true) } } . ",
    "url": "/powershell/#the-ast",
    "relUrl": "/powershell/#the-ast"
  },"43": {
    "doc": "Powershell",
    "title": "POSH things that suck",
    "content": "The requirement for some things where one uses ‘-confirm -force’ and it still asks for user input, e.g. (Though I believe this a faulty implementation by those who made this commandlet.) . I believe the fix here is to run powershell in NonIteractive mode! E.g. see https://serverfault.com/a/642848 . function SetUSUKKeyboard() { Write-Verbose \"Setting uk and us keyboard\" # set call here doesn't care, always stop and waits for user input set-winuserlanguagelist en-GB, en-US -Confirm -Force } . NO! The posh above is wrong, this works . set-winuserlanguagelist en-GB, en-US -Force . The -confirm is actually to ask the user to confirm…. Ruby would have named the parameter Confirm? . Does not have any context-manager equivalent to ‘with’ that python has! As far as I can tell. I think you are required to rely upon try and catch. A common example, a script can only be run from a particular directory. Need to write cd to the directory and if script errors, switch back out of the directory in the catch. Or something like that. Namespaces . In powershell, if you want to get access to some .net class, you can use the full name like this: . # For windows form, we first need the load the assembly using assembly System.Windows.Forms # The [] is the type operator, it says we are specifying the class/type name # This specifies the windows form type [System.Windows.Forms.Form] # But this is obviously quite long to write, so we can load in the namespace which # means we can use [Form] the class using namespace System.Windows.Forms $form = [Form] @{ Text = 'My First Form' } $button = [Button] @{ Text = 'Push Me!' Dock = 'Fill' } $button.add_Click{ $form.Close() } $form.Controls.Add($button) $form.ShowDialog() . However, the namespace syntax is just like pythons from Forms import *. Ahh! How can one know that the [Form] is from System..Windows.Forms rather than some other library? You can’t… . The using namespace &lt;name&gt; means load in a .NET class. Whereas, if you want to load in a powershell module you would write using module &lt;name&gt;. I assume the using assembly &lt;name&gt; means something like load in a dll? . Extract from Powershell in Action about using assembly, . \"\"\"Here are a couple of important points to remember about the using statement. First, it has to be the first non-comment statement in a script or module. This is because, with using, types are resolved at compile time instead of runtime. This is a good thing because it helps you catch your errors sooner. Second, you have to have the assembly containing the reference type namespace loaded before you can run your script. Because a lot of things are loaded by PowerShell by default this isn’t that much of a problem. This is what using assembly &lt;...&gt; is intended for. By specifying both statements as shown in the example, everything will work fine.\"\"\" . Out-string, tricky strings! . Ah it’s easy to get tricked with powershell’s automatic conversion of objects to strings. I had the contents of a file from $lines = Get-Content file.log, when I tried to put it into a string “$lines”, all the newlines were gone. Whoops. Took me a while to find out I needed to use Out-String. From ExpertT: “what you’re seeing is the inbuilt default “Out-Default” function draining remaining objects in the pipeline and rendering them in the ‘default’ way (which is amazingly rich and complex as it happens) but the one truth about powershell is what looks like a string very likely isn’t” . Conver between user names and ssids . Coming from https://community.spiceworks.com/how_to/2776-powershell-sid-to-user-and-user-to-sid . This will give you a Domain User’s SID . $objUser = New-Object System.Security.Principal.NTAccount(\"DOMAIN_NAME\", \"USER_NAME\") $strSID = $objUser.Translate([System.Security.Principal.SecurityIdentifier]) $strSID.Value . This will allow you to enter a SID and find the Domain User . $objSID = New-Object System.Security.Principal.SecurityIdentifier ` (\"ENTER-SID-HERE\") $objUser = $objSID.Translate( [System.Security.Principal.NTAccount]) $objUser.Value . Convert from local user to sid. $objUser = New-Object System.Security.Principal.NTAccount(\"LOCAL_USER_NAME\") $strSID = $objUser.Translate([System.Security.Principal.SecurityIdentifier]) $strSID.Value . Certicates . Powershell provides access to the certstore. That’s where the machines certificates are kept . &gt; ls Cert: Location : CurrentUser StoreNames : {TrustedPublisher, ClientAuthIssuer, Root, UserDS...} Location : LocalMachine StoreNames : {TestSignRoot, ClientAuthIssuer, Remote Desktop, Root...} . Conflicting powershell commands . Powershell doesn’t prevent you importing or overwriting commands with the same name. For instance, the s0s shell defines it’s own Compare-Object command. C:\\Users\\donal.mee&gt; get-command compare-object CommandType Name Version Source ----------- ---- ------- ------ Function Compare-Object 0.0.2 s0s C:\\Users\\donal.mee&gt; get-command -name *compare-object* CommandType Name Version Source ----------- ---- ------- ------ Function Compare-Object 0.0.2 s0s Cmdlet Compare-Object 3.1.0.0 Microsoft.PowerShell.Utility . One way to select the want you want is to remove the offending module . remove-module s0s . But, you can also provide the module name before invoking the command, to be more specific. The source seems to be where to select this. microsoft.powershell.utility\\Compare-Object . s0s\\Compare-Object . Comparing nested objects . There is an in-built compare-object, but try to compare two hashes. Even if their contents are the different or the same the compare-object is useless. It cannot compare nested objects or really objects of much complexity. You need to select the properties that you want to compare it with. ExpertT’s shell has an enhanced compare object and compare dictionary function. The inbuilt one is pretty crap. Write-host host console wtf? . It’s actually hard to capture all the output of the powershell console. It has the idea of streams but a lot of stuff doesn’t write to the streams. This is the problem with write-host. It writes directly to the host program, skips the streams so the user can see it but the console buffers don’t see if. Thus you can’t actually capture the output to a text file. This sucks! . powershell.exe *&gt;&amp;1 &gt; posh.log -command &lt;script that writes to the host directly&gt; # However, the posh.log will only contain output to the host, like the stuff from set-psdebug -trace 1 but it will not contain # the input commands, so all you have is output which is half the puzzle... And even more annoying, lets say you want to trace the execution of a program with set-psdebug -trace 1 and redirect that output to a file. Nope, no luck. It writes directly to the host, not the console. So you effectively can’t capture it. Verbose perference . It doesn’t seem to work. Its not a global thing if it’s set in a script. So your subsequent calls don’t see the verbose preference being set. You probably have to set it as a global preference or something. Classes . POSH classes suck. They are available but can only be loaded as dotnet runtime classes and so you can’t actually load them through the import-module stuff. It’s actually bound once into the runtime and can’t re unloaded, unless there’s some dotnet tricks that will let you do it. POSH seems to expect everyone to use dynamic method/attribute addition methods to build ‘objects’. But it’s sucky objects in my opinion. Catching errors with -erroraction . Actually, you’d think erroraction is respected. It’s not… There’s some commentary above. But basically you can’t know ahead of time whether something is going to use ‘throw’ and so whether you need to wrap it in a try/catch. You basically have to write a parser… see the abstract. Note, how to write a parser for dotnet code is more tricky I suspect. ",
    "url": "/powershell/#posh-things-that-suck",
    "relUrl": "/powershell/#posh-things-that-suck"
  }
}
